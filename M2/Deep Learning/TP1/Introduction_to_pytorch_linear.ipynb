{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "celtic-whale",
   "metadata": {},
   "source": [
    "<img src='https://upload.wikimedia.org/wikipedia/fr/thumb/e/ed/Logo_Universit%C3%A9_du_Maine.svg/1280px-Logo_Universit%C3%A9_du_Maine.svg.png' width=\"300\" height=\"500\">\n",
    "<br>\n",
    "<div style=\"border: solid 3px #000;\">\n",
    "    <h1 style=\"text-align: center; color:#000; font-family:Georgia; font-size:26px;\">Introduction à l'IA</h1>\n",
    "    <p style='text-align: center;'>Master Informatique</p>\n",
    "    <p style='text-align: center;'>Anhony Larcher</p>\n",
    "</div>\n",
    "\n",
    "Ce premier tutoriel est une introduction à [PyTorch](https://pytorch.org/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-period",
   "metadata": {},
   "source": [
    "# Introduction a PyTorch: les classes de base\n",
    "\n",
    "La classe de base en **PyTorch** est le tenseur; les opérations de base sur les tenseurs sont décrites dans la [documentation de **PyTorch**](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)\n",
    "\n",
    "En Pytorch il y a deux façons de définir un réseau de neurone:\n",
    "* dériver la classe **module**\n",
    "* utiliser un objet **sequential**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "figured-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-package",
   "metadata": {},
   "source": [
    "Tout calcul en PyTorch est fait sur un *device* qu'il vous appartient de définir.\n",
    "\n",
    "Généralement, on utilise les **cpu** pour préparer les données et visualiser, et les **gpu** pour le calcul dans les réseaux.\n",
    "\n",
    "```python\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "```\n",
    "\n",
    "## La classe de base pour définir un réseau de neurones est la classe **module**\n",
    "\n",
    "On dérive cette classe pour créer sa propre architecture puis on implémente la fonction **forward**.\n",
    "\n",
    "Nous allons définir un block résiduel (pour implémenter un réseau qui s'inspire d'un ResNet).\n",
    "\n",
    "```python\n",
    "class ResBlock(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    La fonction d'initialisation prend en entrée \n",
    "        * la dimension d'entrée (par défaut 50)\n",
    "        * une liste de 2 entiers qui correspondent aux dimensions des couches cachée intermédiares.\n",
    "          par défaut [128,32]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, à compléter):\n",
    "        super(ResBlock, self).__init__()\n",
    "        ... a completer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ... a completer\n",
    "```\n",
    "\n",
    "La définition d'une classe héritée de `module` requiert l'implémentation de deux méthodes:\n",
    "* ```__init__```\n",
    "* `forward`\n",
    "Le rôle de ces méthodes est détaillé ci-dessous.\n",
    "\n",
    "### Initialisation\n",
    "Instancie les composantes du module:\n",
    "* couches neuronales\n",
    "* fonctions d'activation\n",
    "* couches et fonctions de régularisation (batchnorm, layernorm...)\n",
    "\n",
    "### Méthode `Forward`\n",
    "Définit le flux des données à travers les couches et fonctions instanciées dans la fonction ```__init__```.\n",
    "\n",
    "\n",
    "### Retour à l'exemple du ResBlock\n",
    "\n",
    "Afin d'implémenter votre module vous devez définir son architecture.\n",
    "Dans cet exemple, le bloc doit contenir dans l'ordre:\n",
    "\n",
    "* une première couche linear  avec:\n",
    "    * un biais\n",
    "* une fonction d'activation LeakyRELU\n",
    "* une deuxième couche linear  avec:\n",
    "    * aucun biais\n",
    "* une fonction d'activation Sigmoid\n",
    "* une troisième couche linear  avec:\n",
    "    * un biais\n",
    "    * une dimension de sortie égale à la dimension d'entrée de la première couche\n",
    "* une couche de BatchNorm\n",
    "\n",
    "L'architecture de votre ResBlock est illustrée par la figure suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d2a3cf-54fc-4d5f-9cd7-5a2f474b94d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'gpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c06bb1",
   "metadata": {},
   "source": [
    "<img src='https://git-lium.univ-lemans.fr/cours_m2/open_resources/-/raw/master/figures/dnn_intro_1.png' width=\"300\" height=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "plain-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    La fonction d'initialisation prend en entrée \n",
    "        * la dimension d'entrée (par défaut 50)\n",
    "        * une liste de 2 entiers qui correspondent aux dimensions des couches cachée intermédiares.\n",
    "          par défaut [128,32]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim = 50,  hidden_layout = [128,32]):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim \n",
    "        self.hidden_layout = hidden_layout\n",
    "\n",
    "        # torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)\n",
    "        self.batchNorm = torch.nn.BatchNorm1d(input_dim)\n",
    "        \n",
    "        # torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)\n",
    "        self.linear1 = torch.nn.Linear(input_dim, hidden_layout[0])  # ajouter biais\n",
    "        self.linear2 = torch.nn.Linear(hidden_layout[0], hidden_layout[1], bias = False) \n",
    "        self.linear3 = torch.nn.Linear(hidden_layout[1], input_dim) # ajouter biais et dimension de sortie égale à l'entrée de la couche 1\n",
    "\n",
    "        # torch.nn.LeakyReLU(negative_slope=0.01, inplace=False)\n",
    "        self.leakyRELU = torch.nn.LeakyReLU()\n",
    "\n",
    "        # torch.nn.Sigmoid(*args, **kwargs)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.leakyRELU(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.linear3(out)\n",
    "        out = self.leakyRELU(out)\n",
    "        out = self.batchNorm(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d937753b",
   "metadata": {},
   "source": [
    "### Bonne pratique pour l'implémentation\n",
    "\n",
    "L'implémentation de réseaux de neurones est parfois complexe.\n",
    "Le nombre de couche et la modularité des réseaux nécessite de la rigueur.\n",
    "Une bonne pratique, qui vous évitera un grand nombre d'erreurs consite à vérifier les dimensions d'entrée et de sortie de chaque couche afin de s'assurer que la sortie d'une couche ou d'un module peut être utilisée en entrée du suivant.\n",
    "\n",
    "**Pensez donc à créer un batch de fausses données (au format des vraies) afin de tester votre module au fur et à mesure de son implémentation.**\n",
    "\n",
    "Ici vous pouvez créer un batch de données aléatoires de dimension `(1, 2, 10, 100)` qui correspond à 1 batch de 1 échantillon à 2 canaux de dimension `(10, 100)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fatty-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisez un ResBlock avec une entrée de dimension 20 et des dimensions cachées de 10 et 5\n",
    "rb = ResBlock(20,[10,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "healthy-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1 batch of 100 sample of 20 dimensions\n",
    "data = torch.rand(100, 20)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52897b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of output= torch.Size([100, 20])\n"
     ]
    }
   ],
   "source": [
    "# Test here your module\n",
    "output = rb(data)\n",
    "\n",
    "print(f\"Shape of output= {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-planner",
   "metadata": {},
   "source": [
    "## Sequential\n",
    "\n",
    "### Motivation\n",
    "\n",
    "Un module est très flexible et permet d'implémenter des flux de données complexes.\n",
    "\n",
    "Dans les cas ou le flux de données est simple et (unidirectionnel) il est possible de regrouper des couches ou traitements dans une structure séquentielle.\n",
    "\n",
    "### Application\n",
    "\n",
    "Ré-écrivez maintenant le module ResBlock en utilisant un objet *torch.nn.Sequential*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e31c2f14-4727-41a5-8950-19de2408cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock2(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    La fonction d'initialisation prend en entrée \n",
    "        * la dimension d'entrée (par défaut 50)\n",
    "        * une liste de 2 entiers qui correspondent aux dimensions des couches cachée intermédiares.\n",
    "          par défaut [128,32]\n",
    "    \"\"\"\n",
    "\n",
    "  \n",
    "    def __init__(self, input_dim = 50,  hidden_layout = [128,32]):\n",
    "        super(ResBlock2, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim \n",
    "        self.hidden_layout = hidden_layout\n",
    "\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, hidden_layout[0]),\n",
    "                            torch.nn.LeakyReLU(),\n",
    "                            torch.nn.Linear(hidden_layout[0], hidden_layout[1], bias = False),\n",
    "                            torch.nn.Sigmoid(),\n",
    "                            torch.nn.Linear(hidden_layout[1], input_dim),\n",
    "                            torch.nn.LeakyReLU(),\n",
    "                            torch.nn.BatchNorm1d(input_dim))\n",
    "\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "546b9dd8-929f-46e7-9c13-79f646944e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of output= torch.Size([100, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0289, -0.0187,  0.0689,  ...,  1.6605,  0.0207,  1.3122],\n",
       "        [ 0.0431,  0.0310,  0.0239,  ..., -0.2866,  0.0346, -0.3346],\n",
       "        [ 0.0085,  0.0299,  0.0490,  ..., -0.3898,  0.0112, -1.0373],\n",
       "        ...,\n",
       "        [-0.0410, -0.0118,  0.0046,  ...,  1.0469, -0.0062,  0.5809],\n",
       "        [-0.0088,  0.0027,  0.0306,  ...,  0.1713,  0.0060, -0.0658],\n",
       "        [-0.0127,  0.0072,  0.0370,  ...,  0.7858,  0.0094,  0.1631]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test here your module\n",
    "rb2 = ResBlock2(20,[10,5])\n",
    "output2 = rb2(data)\n",
    "\n",
    "print(f\"Shape of output= {output2.shape}\")\n",
    "rb2.forward(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c7f054-9c75-4e39-a334-b37856aafc09",
   "metadata": {},
   "source": [
    "# Retour sur les modules\n",
    "\n",
    "La classe module est très flexible et permet de créer des **pipelines** complexes comme celui de la figure ci-dessous que nous allons implémenter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861b380f-d436-49f3-b318-e6fb1c85a246",
   "metadata": {},
   "source": [
    "<img src='https://git-lium.univ-lemans.fr/cours_m2/open_resources/-/raw/master/figures/dnn_intro_2.png' width=\"300\" height=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "asian-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=50, hiddens=[128, 64]):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.resBlock1 = ResBlock(input_size,hiddens)\n",
    "\n",
    "        self.resBlock2 = ResBlock2(input_size, hiddens)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        F_X = self.resBlock1(x)\n",
    "        F_F_X = self.resBlock2(F_X)\n",
    "        return identity + F_X + F_F_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adolescent-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciez un ResNet\n",
    "nnet = ResNet(20,[10,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dutch-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créez vos données pour vérifier l'implementation de votre ResNet et testez\n",
    "output = nnet(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "adverse-metallic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of output= torch.Size([100, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5075,  0.3821,  0.6690,  ..., -0.4473,  0.7991,  1.2656],\n",
       "        [ 0.2378, -0.2155,  0.2120,  ...,  0.1371,  0.4747,  0.4346],\n",
       "        [ 0.8827,  0.1168,  0.6713,  ..., -0.3406,  0.1622, -1.4847],\n",
       "        ...,\n",
       "        [ 0.3657, -0.2572,  0.5725,  ...,  0.5019,  0.2576,  1.1354],\n",
       "        [ 0.6937,  0.2434, -0.0081,  ...,  0.3436,  0.7878, -0.0636],\n",
       "        [ 0.2952, -0.0886,  0.2412,  ...,  1.2565,  0.2767,  0.8529]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Shape of output= {output.shape}\")\n",
    "nnet.forward(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-villa",
   "metadata": {},
   "source": [
    "# Datasets, Dataloaders et Datasamplers\n",
    "\n",
    "Les DataSets sont les classes qui permettent de charger et préparer les exemples.\n",
    "\n",
    "Les dataloaders permettent de gérer les batchs\n",
    "\n",
    "Les DataSamplers permettent de définir précisément les données fournies au réseau à chaque époque (équilibrage des batchs, ordre...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "supposed-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910578f8",
   "metadata": {},
   "source": [
    "Implémentez un `DataSet` qui génère une liste de 128 vecteurs de dimension $50$ dont les éléments suivent une distribution normale.\n",
    "Lorsque la méthode `__getitem__` est appelée, le `DataSet` retourne la matrice correspondante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "spiritual-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        de nombreuses transformations existent qui permettent d'augmenter les données simplement\n",
    "        \"\"\"\n",
    "        self.data = np.random.randn(128*50).reshape(128,50)\n",
    "        self.labels = np.random.randint(0,10,128)\n",
    "        \n",
    "        self.len = len(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae6b70f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension des données: (50,)\n",
      "label associé à cet échantillon: 1\n"
     ]
    }
   ],
   "source": [
    "# Instanciez et testez votre RandomDataset en affichant le 3e exemple généré\n",
    "training_set = RandomDataset()\n",
    "training_set.__getitem__(2)\n",
    "print(f\"dimension des données: {training_set.__getitem__(2)[0].shape}\")\n",
    "print(f\"label associé à cet échantillon: {training_set.__getitem__(2)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "protecting-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créez un DataLoader qui utilise votre RandomDataset pour générer des batchs de 16 échantillons tirés dans un ordre aléatoire.\n",
    "# Attention il est possible que l'environnement du notebook ne vous permette pas de lancer ce DataLoader.\n",
    "# Si c'est le cas, pourquoi?\n",
    "\n",
    "# Pour résoudre ce problème recopiez le code du RandomDataset dans un module python externe que vous importerez ensuite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8de82953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichez le nombre de batchs générés par votre DataLoader\n",
    "len(training_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008dbb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testez ce DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dfe83a",
   "metadata": {},
   "source": [
    "## DataSampler\n",
    "\n",
    "Implementez un data sampler qui, parmi les 128 exemples du dataset, sélectionne ces échantillons aléatoirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "necessary-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler(torch.utils.data.Sampler):\n",
    "    \"\"\"\n",
    "    Data Sampler used to generate uniformly distributed batches\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a82f8",
   "metadata": {},
   "source": [
    "Utilisez votre `DataSampler` avec un DataLoader qui n'effectue pas de shuffle sur vos données et vérifier son fonctionnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "natural-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "from randomset import RandomDataset2\n",
    "training_set = RandomDataset2()\n",
    "sampler = BatchSampler(16)\n",
    "\n",
    "training_loader = DataLoader(training_set,\n",
    "                             batch_size=16,\n",
    "                             shuffle=False,\n",
    "                             drop_last=True,\n",
    "                             pin_memory=True,\n",
    "                             #sampler=sampler,\n",
    "                             num_workers=1,\n",
    "                             persistent_workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3dbf1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7937,  1.4512, -0.4704,  ...,  0.0145, -0.2925,  0.9257],\n",
      "         [-0.0340, -0.0792,  0.0186,  ...,  0.1165, -1.1145, -0.8483],\n",
      "         [-3.5411,  0.4113, -1.2204,  ...,  1.1191, -0.2236,  0.1004],\n",
      "         ...,\n",
      "         [-0.7605,  0.1050,  1.8894,  ...,  0.5267,  1.4374, -0.3940],\n",
      "         [ 0.3630, -0.8052,  0.9325,  ...,  0.7135,  0.6261,  0.4511],\n",
      "         [ 1.2429, -0.8078, -0.5532,  ...,  0.2315, -0.7555, -0.1166]],\n",
      "\n",
      "        [[-1.8358,  1.1586,  0.8221,  ...,  0.7761,  3.3134,  1.5142],\n",
      "         [ 0.6716,  0.7796, -1.6265,  ..., -1.6118, -1.1040, -0.3088],\n",
      "         [ 0.0318,  1.0291,  0.9390,  ...,  3.0728,  0.1594,  0.8606],\n",
      "         ...,\n",
      "         [ 0.4851,  1.0680,  1.5948,  ...,  0.2656, -0.1093,  0.3473],\n",
      "         [ 1.0904,  0.6719, -0.9522,  ..., -0.9245,  0.5239, -0.9447],\n",
      "         [-0.5843,  0.8847,  0.3747,  ...,  0.3761,  1.5945, -0.5665]],\n",
      "\n",
      "        [[ 1.4093, -0.5195,  0.6137,  ..., -1.1289, -0.4026, -0.4182],\n",
      "         [ 1.2400,  2.1219, -1.1617,  ..., -0.4130,  0.2008, -0.6908],\n",
      "         [-0.2330,  0.0652,  0.5499,  ...,  0.6058,  1.7121,  0.0068],\n",
      "         ...,\n",
      "         [ 0.1749,  0.7058, -0.2256,  ..., -0.3942,  1.1496, -0.8263],\n",
      "         [ 0.7890, -1.4967, -1.2376,  ...,  0.8547,  1.0278,  0.3913],\n",
      "         [-1.5943,  1.1132, -1.3562,  ...,  1.8552,  0.3676,  0.4442]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2737,  1.3287, -1.0857,  ...,  0.2225,  1.1444,  0.3060],\n",
      "         [ 0.9535,  0.8009, -1.1988,  ...,  0.0958,  0.5612,  0.9556],\n",
      "         [ 0.9370,  0.3904, -0.7262,  ...,  1.2768, -0.3180,  0.3073],\n",
      "         ...,\n",
      "         [ 2.9416,  0.0971, -0.1896,  ..., -1.6517,  1.4536, -0.1615],\n",
      "         [-0.2503, -0.3555,  1.3142,  ..., -2.2225,  0.9119, -1.0122],\n",
      "         [ 0.6534, -0.8491,  0.0355,  ..., -0.3168,  0.8339,  0.4632]],\n",
      "\n",
      "        [[-0.1588, -0.6607,  0.3493,  ..., -0.7937,  0.1308,  0.7998],\n",
      "         [-0.3466, -0.0877, -0.2799,  ...,  0.4063,  0.6529, -0.0307],\n",
      "         [ 0.3032, -0.2027, -2.4951,  ...,  0.1612,  0.5355, -0.0533],\n",
      "         ...,\n",
      "         [-0.5148,  0.2813, -0.6869,  ..., -0.3230,  0.3150,  0.6275],\n",
      "         [ 1.0678,  0.2062,  0.1222,  ..., -0.5308,  0.3217,  0.8967],\n",
      "         [-1.2882,  0.1734, -0.1594,  ...,  0.8041, -0.5580,  0.9535]],\n",
      "\n",
      "        [[ 0.4154, -2.7517,  0.3386,  ...,  0.9554,  2.0445,  0.5655],\n",
      "         [-0.8410, -0.0157,  0.6403,  ...,  0.2505,  0.0305, -0.6627],\n",
      "         [-1.5436, -0.1857,  1.4460,  ...,  0.2461, -0.4938,  0.4567],\n",
      "         ...,\n",
      "         [ 0.5482, -0.6584,  0.9507,  ...,  0.7308, -0.7846, -1.1305],\n",
      "         [-0.8798, -0.9287, -0.1887,  ..., -1.2710, -0.0673,  1.6927],\n",
      "         [-0.6566,  0.3791,  0.0899,  ...,  1.5301, -0.8729, -0.2183]]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Testez ce DataLoader\n",
    "for batch_idx, (data, target) in enumerate(training_loader):\n",
    "    if batch_idx == 1:\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c36fa08",
   "metadata": {},
   "source": [
    "# Save and Load models\n",
    "\n",
    "It is advised to save and load models to use the **load_state_dict** method.\n",
    "\n",
    "Beware, saving and loading models requires to know on which device the model is loaded.\n",
    "\n",
    "*Question: How to load a model on a selected device?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14212a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load your model here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47bb29",
   "metadata": {},
   "source": [
    "# Make PyTorch deterministic\n",
    "\n",
    "Randomness is very present in many steps of deep learning.\n",
    "\n",
    "In order to come closer to reproducibility you need to :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb6b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "import torch\n",
    "\n",
    "numpy.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430771ed",
   "metadata": {},
   "source": [
    "Convolution can involve the choice of different algorithms.\n",
    "\n",
    "**When a cuDNN convolution is called with a new set of size parameters, an optional feature can run multiple convolution algorithms, benchmarking them to find the fastest one.**\n",
    "\n",
    "Disabling the benchmarking feature with ```torch.backends.cudnn.benchmark = False``` causes cuDNN to deterministically select an algorithm, possibly at the cost of reduced performance.\n",
    "\n",
    "However, if you do not need reproducibility across multiple executions of your application, then performance might improve if the benchmarking feature is enabled with ```torch.backends.cudnn.benchmark = True```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b99b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0003e6",
   "metadata": {},
   "source": [
    "DataLoader will reseed workers following Randomness in multi-process data loading algorithm. \n",
    "\n",
    "Use ```worker_init_fn()``` and generator to preserve reproducibility:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
