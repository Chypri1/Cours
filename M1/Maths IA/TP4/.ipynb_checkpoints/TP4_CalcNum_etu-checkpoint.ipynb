{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4: Overflow/underflow et Descente de Gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1 : Descente de gradient\n",
    "\n",
    "Nous allons maintenant travailler sur la fonction $g(x,y) = x^2 + \\sin(y)$ que nous avons étudié au TP3.\n",
    "\n",
    "On rappelle qu'une dérivée partielle peut être soit définie explicitement avec une formule mathématique issue du calcul des dérivées (vu dans le TP3), soit obtenue grâce aux accroissements finis. Dans ce TP, nous allons utiliser l'approximation suiante pour le calcul de la dérivée parielle suivant la variable $x$ au point $(x_0, y_0)$:\n",
    "\n",
    "$$\\dfrac{\\partial f}{\\partial x}(x_0,x_0) \\approx \\dfrac{f(x_0+ \\epsilon,y_0) - f(x_0-\\epsilon, y_0)}{2\\epsilon}$$\n",
    "\n",
    "On rappelle également que le gradient de la fonction $g$ au point $(x_0, y_0)$ s'exprime:\n",
    "\n",
    "$$\\nabla g(x_0, y_0) = \\left(\\dfrac{\\partial g}{\\partial x}(x_0, y_0); \\dfrac{\\partial g}{\\partial y}(x_0, y_0)\\right)$$\n",
    "\n",
    "Si on cherche un minimum de la fonction, on va alors chercher les conditions du 1er ordre (CPO) et annuler le gradient pour déterminer le point $(x_0, y_0)$:\n",
    "$$\\nabla g(x_0, y_0) = \\mathbf{0}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x[0]**2 + np.sin(x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** Écrire une fonction qui calcule le gradient d'une fonction de plusieurs variables par différences finies au point $\\mathbf{x}$. Elle doit prendre en entrée un vecteur $\\mathbf{x} \\in \\mathbb{R}^n$. Et retourner le gradient, donc un vecteur de dimension $n$ également.\n",
    "- [ ] vérifier que votre fonction fonctionne avec plusieurs dimensions.\n",
    "- [ ] vérifier que si $\\mathbf{x} \\in \\mathbb{R}^n$ alors votre fonction retourne bien un vecteur de taille $n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grad(X, func):\n",
    "    eps = 0.00001\n",
    "    dfdX = (func((X[0] + eps, X[1])) - func((X[0]-eps, X[1]))) / 2*eps\n",
    "    dfdY = (func((X[0], X[1] + eps)) - func((X[0], X[1] - eps))) / 2*eps\n",
    "    return (dfdX, dfdY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 5.403023058569989e-11) 0.5403023058681398\n"
     ]
    }
   ],
   "source": [
    "print(grad((0, 1), f), np.cos(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Écrire l'algorithme de descente pour une fonction à deux variables. On considèrera que l'algorithme a trouvé la solution si la norme du gradient est proche de 0 soit par exemple : `np.linalg.norm(G) < tol`, la variable `tol` correspond à votre seuil de tolérance.\n",
    "- [ ] ajouter un seuil de tolérance en entrée de l'algorithme. \n",
    "- [ ] définir un nombre d'itération maximum `Niter` tel que l'algorithme s'arrête après `Niter` même si il n'a pas approché suffisamment la solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha = 0.8\n",
    "def descente(func, alpha, Niter):\n",
    "    X = (1.5, 0.3)\n",
    "    G = grad(X, func)\n",
    "    \n",
    "    ii = ii + 1\n",
    "    \n",
    "    if((np.linalg.norm(G) < alpha) or ii > Niter):\n",
    "        return (grad, ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** Afin de pouvoir visualiser l'algorithme de descente, modifier votre algorithme de descente afin qu'il retourne non seulement la valeur de minimum trouvé, mais aussi la suite des valeurs $(\\mathbf{x}_n)$ par lesquelles il est passé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** Choisir un point pour l'initialisation et une valeur de vitesse d'apprentissage à partir de l'étude de la fonction réalisée au TP3.<br>\n",
    "Réaliser la descente de gradient et donner l'optimum trouvé, ainsi que le nombre d'itérations nécessaires pour converger vers cette solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** Afin de visualiser l'algorithme de descente, tracer les contours de $g$ sur un plan en 2D. Et afficher la suite des valeurs $(\\mathbf{x}_n)$ par lesquelles l'algorithme est passé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_():\n",
    "    x = ??\n",
    "    y = ??\n",
    "    x,y = np.meshgrid(x, y)\n",
    "    z = x**2 + np.sin(y)\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    axes = fig.gca()\n",
    "    axes.contour(x, y, z, 21) \n",
    "    axes.plot(...., ’−+r’) \n",
    "    axes.set_title('z = x^2 + sin(y)') \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6.** Faites varier le point de départ $\\mathbf{x}_0$ puis la vitesse d'apprentissage $\\alpha$. Observer les effets induits sur la valeur de la solution à l'aide du graphique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 : Régression logistique\n",
    "\n",
    "On définit nos données *data*. L'objectif est d'apprendre à reconnaître les tumeurs malignes (*y=1*) des tumeurs bénignes (*y=0*) en fonction de la taille de la tumeur (*x*).\n",
    "\n",
    "L'objectif ici sera également de déterminer les paramètres du modèle optimum, sachant que nous avons cette fois une formulation explicite du gradient pour la fonction logistique. Il ne sera donc pas nécessaire de passer par le calcul des différences finies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(xs,ys):\n",
    "    \n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.spines['left'].set_position('center')\n",
    "    ax.spines['bottom'].set_position('zero')\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.set_xlabel('taille de la tumeur')\n",
    "    ax.set_ylabel('malignité')\n",
    "\n",
    "    # plot the function\n",
    "    plt.plot(xs,ys, 'r') \n",
    "    \n",
    "data=[(0,0), (1,0), (3,0), (5,0), (7,0), (7,1), (8,1), (10,1), (12,1)]\n",
    "xdata=[x for (x,y) in data]\n",
    "ydata=[y for (x,y) in data]\n",
    "plt.figure()\n",
    "for x,y in data:\n",
    "    if y ==1:\n",
    "        plt.scatter(x, y, color='red', alpha=.8)\n",
    "    else:\n",
    "        plt.scatter(x, y, color='blue', alpha=.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** On choisit de modéliser notre classifieur comme une régression logistique basée sur la fonction sigmoïde donnée ci-dessous. Puisque nos données sont représentées sur une seule dimension, nous avons deux paramètres à apprendre, *theta0* et *theta1*.\n",
    "$$\\hat{y}_i = \\sigma(x_i, \\theta_0, \\theta_1) = \\dfrac{1}{1 + e^{- \\theta_1 x_i - \\theta_0}}$$\n",
    "\n",
    "En utilisant le fonction `plot` définie plus haut, tracer la fonction sigmoïde entre -12 et 12. Vous commencerez par *theta0=0* et *theta1=1*, puis vous ferez varier ces paramètres pour visualiser l'effet sur la fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(-12,12,100)\n",
    "\n",
    "#La sigmoïde telle que décrite dans les livres avec les moins devant tous nos paramètres theta\n",
    "def sigma(x, teta0, teta1):\n",
    "    return 1/(1+np.exp(-teta0 - teta1 * x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Une fois que l'on connait l'impact de theta0 et theta1, on peut s'amuser à essayer de trouver nous mêmes ces paramètres comme ci-dessous, avec une régression logistique qui classifierait plutôt bien nos données.\n",
    "\n",
    "Afficher sur le même graphique, vos données et la fonction sigmoïde (entre -12 et 12 donc). Vous définirez un jeu de paramètres (theta0, theta1) qui permet à la fonction de s'approcher au mieux des données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** Dans le cas de la régression logistique, on cherche à réaliser une classification binaire. On utilisera alors la fonction de coût BCE (Binary Cross-Entropy). Le coût global s'écrit comme la somme des coûts locaux:\n",
    "\n",
    "$$J(\\theta) = \\dfrac{1}{N} \\sum_{i=1}^N J_i (\\theta)$$\n",
    "\n",
    "Et le coût local s'écrit:\n",
    "$$J_i(\\theta) = - \\left[y_i \\log(\\sigma(x_i, \\theta)) + (1 - y_i)\\log(1-\\sigma(x_i, \\theta))\\right] $$\n",
    "\n",
    "* [ ] La fonction de coût est censée pénaliser les valeurs de `theta` qui entraine un éloignement de la valeur prédite par rapport à la valeur de référence. Faites le lien avec la définition mathématique ci-dessus. Notamment quel est l'intérêt d'introduire un logarithme.\n",
    "* [ ] Quel est l'inconvénient du logarithme dans ce cas ?\n",
    "* [ ] Implémenter cette fonction de coût globale, que l'on notera `jobj`\n",
    "* [ ] Observer les valeurs retournées par `jobj` en fonction des différentes valeurs de `theta0, theta1` que vous avez testé auparavant. L'erreur doit être de plus en plus faible lorsqu'on s'approche du paramètre optimal.\n",
    "\n",
    "Tout d'abord, on calcule la fonction d'erreur *jobj* qu'il s'agit de minimiser, puisque c'est une fonction d'erreur. On constate que l'erreur du modèle *fitté* à la main est faible.\n",
    "\n",
    "theta0=-7 ; theta1=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** La fonction à minimiser est ici la fonction de coût $J(\\theta)$, il faut donc définir son gradient sur les paramètres *theta0* et *theta1*. Nous avons montré en cours une formulation explicite du gradient avec les formules suivantes:\n",
    "$$\\dfrac{\\partial J}{\\partial \\theta_0}(\\theta) = \\hat{y}_i - y_i $$\n",
    "$$\\dfrac{\\partial J}{\\partial \\theta_1}(\\theta) = x_i (\\hat{y}_i - y_i) $$\n",
    "\n",
    "Dans un premier temps : \n",
    "- [ ] Implémenter une fonction `deltajtheta0` qui prend en entrée un vecteur d'entrée `xdata`, les valeurs de références associées `ydata` et les paramètres du modèle, ici `theta0, theta1`. Cette fonction retourne le gradient sur *theta0*.\n",
    "- [ ] Proposer une descente de gradient sur 100 itérations, avec une vitesse d'apprentissage de 1. Vous ajouterez une visualisation de la convergence en fonction des itérations. En partant de (theta0=0 ; theta1=1), on va apprendra via le gradient le paramètre *theta0* qui converge presque vers *-7*.\n",
    "- [ ] Varier la vitesse d'apprentissage et observer la convergence\n",
    "\n",
    "Dans un second temps:\n",
    "- [ ] Implémenter une fonction `deltajtheta1` qui prend en entrée un vecteur d'entrée `xdata`, les valeurs de références associées `ydata` et les paramètres du modèle, ici `theta0, theta1`. Cette fonction retourne le gradient sur *theta1*.\n",
    "- [ ] Proposer une descente de gradient sur 100 itérations, avec une vitesse d'apprentissage de 1 sur *theta0* et 0.3 sur *theta1*. Vous ajouterez une visualisation de la convergence en fonction des itérations. En partant de (theta0=0 ; theta1=1), on va apprendra via le gradient les paramètres *theta0* et *theta1*. On obtient une erreur encore plus faible avec cette optimisation !\n",
    "- [ ] Varier les vitesses d'apprentissage et observer la convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 3: Overflow / Underflow\n",
    "\n",
    "**Q1.** Est-ce que l'égalité suivante : `0.1 + 0.1 + 0.1 == 0.3` est vraie en Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En binaire, la fraction décimale `0.125` s'écrit sous la forme $$0 \\cdot 10^0 + 1 \\cdot 10^{-1} + 2 \\cdot 10^{-2} + 5 \\cdot 10^{-3}$$\n",
    "De la même manière, la fraction binaire `0.001` peut s'écrire sous la forme`\n",
    "$$0 \\cdot 2^0 + 0 \\cdot 2^{-1} + 0 \\cdot 2^{-2} + 1 \\cdot 2^{-3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** En utilisant le format d'affichage des flottants en python, par exemple `'%.2f' % 0.1` \n",
    "- [ ] donner la valeur exacte en décimale de l'approximation en binaire stockée en machine pour `0.1`,\n",
    "- [ ] expliquer, à présent, votre résultat à la première question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** Que se passe-t-il lorsque l'on multiplie deux valeurs proches de 0 à l'aide d'un ordinateur?<br>\n",
    "Vous testerez la multiplication sur plusieurs valeurs en faisant varier la puissance de 10.\n",
    "Vous pouvez vérifier le résultat du produit en le comparant à `0.0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** Implémenter la fonction `softmax(x)` vue en cours.\n",
    "- [ ] Vérifier que le résultat est cohérent avec le vecteur de nombres aléatoires `a` donné ci-dessous.\n",
    "- [ ] Tester le résultat avec un vecteur aléatoire de grands nombres (puissance de 10). \n",
    "- [ ] Par rapport aux ordres de grandeurs trouvés à la question précédente, vous devriez trouver des `nan` ou des `0` pour une puissance de 10 beaucoup plus faible. Expliquer\n",
    "- [ ] Faire le changement de variable proposé en cours. Qu'est-ce que cela change ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** On cherche maintenant à implémenter une fonction `logsoftmax` qui prend le log du résultat retourné par la fonction softmax définie à la question Q4.\n",
    "- [ ] Que se passe-t-il si le résultat de la fonction `softmax` est nul (underflow) ?\n",
    "- [ ] Montrer que le changement de variable $z_i = x_i - \\max_i x_i$ permet de résoudre ce problème. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour confirmer vos choix, vous pouvez regarder le code source des fonctions `softmax` et `log_softmax` implémentées dans la librairie scipy.<br>\n",
    "https://github.com/scipy/scipy/blob/v1.9.2/scipy/special/_logsumexp.py#L130-L223"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
